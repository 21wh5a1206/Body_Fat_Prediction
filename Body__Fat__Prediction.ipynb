{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSdmKUtbGYcf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxGPAccfEjH2",
        "outputId": "a6ae8b30-c0c0-4759-f886-46614b4e3cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "G61Kl6LSK7dk",
        "outputId": "e208d733-e240-49ce-b84d-b297b91483a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4f5b336068c3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bodyfat.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bodyfat.csv'"
          ]
        }
      ],
      "source": [
        "# Import dataset\n",
        "df = pd.read_csv(\"bodyfat.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9d2AM6_LCq9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVR_X6d3LEpC"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yntoYVDhLgNf"
      },
      "outputs": [],
      "source": [
        "# define a distribution function\n",
        "def plot_displots(col):\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    sns.kdeplot(df[\"BodyFat\"], color=\"magenta\",\n",
        "                label=\"Bodyfat\")\n",
        "    sns.kdeplot(df[col], color=\"red\",\n",
        "                label=col)\n",
        "    plt.legend();\n",
        "    plt.show()\n",
        "\n",
        "cols =list(df.columns)\n",
        "for i in cols:\n",
        "    print(f\"Distribution plots for {i} feature is shown below\")\n",
        "    plot_displots(i);\n",
        "    print(\".\"*100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFJBD-nYMlLm"
      },
      "outputs": [],
      "source": [
        "# function that plots the distribution\n",
        "def draw_plots(df, col):\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.hist(df[col], color=\"magenta\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    stats.probplot(df[col], dist=\"norm\", plot=plt)\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    sns.boxplot(df[col], color=\"magenta\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "cols = list(df.columns)\n",
        "for i in range(len(cols)):\n",
        "\n",
        "    print(f\"Distribution plots for the feature {cols[i]} are shown below \")\n",
        "\n",
        "    draw_plots(df, cols[i])\n",
        "\n",
        "    print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEFZPCNoMwld"
      },
      "outputs": [],
      "source": [
        "#Checking for outliers\n",
        "upper_limit = []\n",
        "lower_limit = []\n",
        "for i in df.columns:\n",
        "    upper_limit.append(df[i].mean() + (df[i].std())*4)\n",
        "    lower_limit.append(df[i].mean() - (df[i].std())*4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJyMH_9XM3PR"
      },
      "outputs": [],
      "source": [
        "cols = list(df.columns)\n",
        "j = 0\n",
        "for i in range(len(cols)):\n",
        "\n",
        "    temp = df.loc[(df[cols[i]]>upper_limit[j])&(df[cols[i]]<lower_limit[j])]\n",
        "    j += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htTm9Q2sM7zf"
      },
      "outputs": [],
      "source": [
        "temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18a6v_mkNAhU"
      },
      "outputs": [],
      "source": [
        "# We will create a copy of the data frame\n",
        "data = df.copy()\n",
        "\n",
        "# get the target label\n",
        "y = data[\"BodyFat\"]\n",
        "\n",
        "# get the predictive varable\n",
        "X = data.drop(columns=[\"BodyFat\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d76WPOJ0NFPj"
      },
      "outputs": [],
      "source": [
        "# import ExtraTrees Regressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# instantiate ExtrareeRegressor\n",
        "er = ExtraTreesRegressor()\n",
        "\n",
        "# Fit the Features and target labels\n",
        "er.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElUnZEmwNKSW"
      },
      "outputs": [],
      "source": [
        "# get the feature importances into a pandas series\n",
        "series = pd.Series(er.feature_importances_, index=X.columns)\n",
        "series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odc7Z6iVNPYe"
      },
      "outputs": [],
      "source": [
        "# plot a graph of the top 5 feature importance scores\n",
        "series.nlargest(5).plot(kind=\"barh\", color=\"green\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOSh42VsNUDw"
      },
      "outputs": [],
      "source": [
        "# import mutual info regression\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# instanciate mutual_info_regression\n",
        "mr = mutual_info_regression(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loB8XgrnZfyy"
      },
      "outputs": [],
      "source": [
        "plot_data = pd.Series(mr, index=X.columns)\n",
        "plot_data.nlargest(5).plot(kind=\"barh\", color=\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxAVv0x-ZmJQ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy0gxGfSNWU_"
      },
      "outputs": [],
      "source": [
        "# Plot correlation map\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(data.corr(), annot=True, cmap=\"plasma\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yhmt4r0Nfpx"
      },
      "outputs": [],
      "source": [
        "# defin a correlation threshold function function\n",
        "def correlation(df, threshold):\n",
        "\n",
        "    col_cor = set()\n",
        "\n",
        "    cor_mat = df.corr()\n",
        "\n",
        "    for i in range(len(cor_mat)):\n",
        "\n",
        "         for j in range(i):\n",
        "\n",
        "                '''\n",
        "                for each cell, get the value of that cell by\n",
        "                .loc[i][j], where i is th row and j is the col.\n",
        "                If the absolute value is greater that the threshold,\n",
        "                get the colum_name and add it in the set\n",
        "                '''\n",
        "\n",
        "                if abs(cor_mat.iloc[i][j]) > threshold:\n",
        "                    col_name = cor_mat.columns[i]\n",
        "                    col_cor.add(col_name)\n",
        "\n",
        "    return col_cor\n",
        "\n",
        "ans = correlation(X, threshold=0.85)\n",
        "\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5YELTJINkkp"
      },
      "outputs": [],
      "source": [
        "X.corr()[['Abdomen', 'Chest', 'Hip', 'Knee', 'Thigh']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKXWBp3QNp4Q"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uyP2JObNuxO"
      },
      "outputs": [],
      "source": [
        "# copy data\n",
        "temp = data[list(data.columns)]\n",
        "info = pd.DataFrame()\n",
        "\n",
        "# Get varianve importance score\n",
        "info[\"VIF\"] = [variance_inflation_factor(temp.values, i) for i in range(temp.shape[1])]\n",
        "info[\"Columns\"] = temp.columns\n",
        "info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXXKCqY9Nz_q"
      },
      "outputs": [],
      "source": [
        "info.sort_values(by=\"VIF\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-2V-uG3N4iW"
      },
      "outputs": [],
      "source": [
        "col_1 = list(series.nlargest(5).index)\n",
        "col_2 = list(plot_data.nlargest(5).index)\n",
        "\n",
        "col_1, col_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EcKvDI4OLhV"
      },
      "outputs": [],
      "source": [
        "to_train = X[col_1]\n",
        "to_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwIDuI03OS_e"
      },
      "outputs": [],
      "source": [
        "# Import modules to build model\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfobW9ZLPb_z"
      },
      "outputs": [],
      "source": [
        "# Split the data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(to_train, y,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VUEUFXgpwYu"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYlTpQXNPgwi"
      },
      "outputs": [],
      "source": [
        "# Build a decision tree model\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veC-xBEOPrGQ"
      },
      "outputs": [],
      "source": [
        "# Plot tree\n",
        "plt.figure(figsize=(10, 7))\n",
        "tree.plot_tree(reg, filled=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8cSN788depG"
      },
      "outputs": [],
      "source": [
        "# prune the decision tree\n",
        "path = reg.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alpha = path.ccp_alphas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR8JJuBwqBym"
      },
      "outputs": [],
      "source": [
        "# train different models with different ccp_alpha values\n",
        "alpha_list = []\n",
        "for i in range(len(ccp_alpha)):\n",
        "    reg = DecisionTreeRegressor(ccp_alpha=ccp_alpha[i])\n",
        "    reg.fit(X_train, y_train)\n",
        "    alpha_list.append(reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdzbfEVBqGO9"
      },
      "outputs": [],
      "source": [
        "# get the train and test scores\n",
        "train_score = [alpha_list[i].score(X_train, y_train) for i in range(len(alpha_list))]\n",
        "\n",
        "test_score = [alpha_list[i].score(X_test, y_test) for i in range(len(alpha_list))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92MRYQauqoUr"
      },
      "outputs": [],
      "source": [
        "# Plot the train and test scores\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(ccp_alpha, train_score, marker=\"o\", label=\"training\",\n",
        "        color=\"blue\", drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alpha, test_score, marker=\"o\", label=\"testing\",\n",
        "        color=\"red\", drawstyle=\"steps-post\");\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt9EjOB1qtqE"
      },
      "outputs": [],
      "source": [
        "# Normal approach\n",
        "clf = DecisionTreeRegressor(ccp_alpha=1)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(f\"Decision Tree Base Model: {metrics.r2_score(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbFzBFfqyAu"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf_base = RandomForestRegressor(n_estimators=1000, ccp_alpha=1)\n",
        "rf_base.fit(np.array(X_train), y_train)\n",
        "y_pred_rf = rf_base.predict(np.array(X_test))\n",
        "print(f\"Random Forest Base Model: {metrics.r2_score(y_test, y_pred_rf)} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfDddgMu1Ahe"
      },
      "outputs": [],
      "source": [
        "# Gradient boosting\n",
        "gb_base = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1)\n",
        "gb_base.fit(np.array(X_train), y_train)\n",
        "y_pred_gb = gb_base.predict(np.array(X_test))\n",
        "gb_r2 = metrics.r2_score(y_test, y_pred_gb)\n",
        "print(f\"Gradient Boosting Base Model: {gb_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu3ESmcP1QvT"
      },
      "outputs": [],
      "source": [
        "# Ada Boosting\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "ab_base = AdaBoostRegressor(n_estimators=1000, learning_rate=0.1)\n",
        "ab_base.fit(np.array(X_train), y_train)\n",
        "y_pred_ab = ab_base.predict(np.array(X_test))\n",
        "ab_r2 = metrics.r2_score(y_test, y_pred_ab)\n",
        "print(f\"AdaBoost Base Model: {ab_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-fSeN191mbm"
      },
      "outputs": [],
      "source": [
        "# Support vector regressor\n",
        "svr_base = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
        "svr_base.fit(np.array(X_train), y_train)\n",
        "y_pred_svr = svr_base.predict(np.array(X_test))\n",
        "svr_r2 = metrics.r2_score(y_test, y_pred_svr)\n",
        "print(f\"Support Vector Regressor Base Model: {svr_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUQC_oOB1oCD"
      },
      "outputs": [],
      "source": [
        "# Artificial Neural Network\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "ann_base = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', alpha=0.0001, max_iter=1000, random_state=42)\n",
        "ann_base.fit(X_train, y_train)\n",
        "y_pred_ann = ann_base.predict(X_test)\n",
        "ann_r2 = metrics.r2_score(y_test, y_pred_ann)\n",
        "print(f\"Artificial Neural Network Base Model: {ann_r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPugJe-kq7Vq"
      },
      "outputs": [],
      "source": [
        "# get the values for hyperparameter tuning\n",
        "params = {\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestRegressor(),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [int(x) for x in np.linspace(start=1, stop=1200, num=10)],\n",
        "            \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "            \"max_depth\": [int(x) for x in np.linspace(start=1, stop=30, num=5)],\n",
        "            \"min_samples_split\": [2,5,10,12],\n",
        "            \"min_samples_leaf\": [2,5,10,12],\n",
        "            \"max_features\": [\"auto\", \"sqrt\"],\n",
        "            \"ccp_alpha\":[1,2,2.5,3,3.5,4,5]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"DecisionTree\": {\n",
        "        \"model\": DecisionTreeRegressor(),\n",
        "        \"params\": {\n",
        "            \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
        "            \"splitter\": [\"best\", \"random\"],\n",
        "            \"min_samples_split\": [1,2,5,10,12],\n",
        "            \"max_features\": [\"auto\", \"sqrt\"],\n",
        "            \"ccp_alpha\":[1,2,2.5,3,3.5,4,5]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"SVM\": {\n",
        "        \"model\": SVR(),\n",
        "        \"params\": {\n",
        "            \"C\": [0.25, 0.5, 0.75, 1.0],\n",
        "            \"tol\": [1e-10, 1e-5, 1e-4, 0.025, 0.50, 0.75],\n",
        "            \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "            \"max_iter\": [int(x) for x in np.linspace(start=1, stop=250, num=10)]\n",
        "        }\n",
        "    },\n",
        "    \"AdaBoost\" : {\n",
        "    \"model\": AdaBoostRegressor(),\n",
        "    \"params\": {\n",
        "        \"n_estimators\": [50, 100, 200, 500],\n",
        "        \"learning_rate\": [0.01, 0.1, 1.0],\n",
        "    }\n",
        "},\n",
        "    \"GradientBoosting\" : {\n",
        "    \"model\": GradientBoostingRegressor(),\n",
        "    \"params\": {\n",
        "        \"n_estimators\": [50, 100, 200, 500],\n",
        "        \"learning_rate\": [0.01, 0.1, 1.0],\n",
        "        \"max_depth\": [3, 4, 5, 6],\n",
        "    }\n",
        "    },\n",
        "    \"NeuralNetwork\" : {\n",
        "    \"model\": MLPRegressor(),\n",
        "    \"params\": {\n",
        "        \"hidden_layer_sizes\": [(50, 25), (100, 50), (200, 100)],\n",
        "        \"activation\": ['relu', 'tanh'],\n",
        "        \"alpha\": [0.0001, 0.001, 0.01],\n",
        "        \"max_iter\": [500, 1000],\n",
        "    }\n",
        "}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJolx2Txq_4f"
      },
      "outputs": [],
      "source": [
        "# Execute RandomizedSearchCV and get best parameters\n",
        "scores = []\n",
        "for model_name, model_params in params.items():\n",
        "    clf = RandomizedSearchCV(model_params[\"model\"],\n",
        "                            param_distributions=model_params[\"params\"],\n",
        "                            cv=5, n_jobs=-1, n_iter=10,\n",
        "                            scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    scores.append({\n",
        "        \"model_name\": model_name,\n",
        "        \"best_score\": clf.best_score_,\n",
        "        \"best_estimator\": clf.best_estimator_\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_o2xJaGrHWm"
      },
      "outputs": [],
      "source": [
        "# view scores\n",
        "scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_LOrxzbrKx8"
      },
      "outputs": [],
      "source": [
        "# create a data frame of the scores\n",
        "scored_df = pd.DataFrame(scores, columns=[\"model_name\",\n",
        "                                          \"best_score\",\n",
        "                                          \"best_estimator\"])\n",
        "\n",
        "scored_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utjOBkT8rRoZ"
      },
      "outputs": [],
      "source": [
        "scores[4][\"best_estimator\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVcblrFQrYy8"
      },
      "outputs": [],
      "source": [
        "# train the model with best parameters\n",
        "gb = scores[4][\"best_estimator\"]\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gb.predict(X_test)\n",
        "\n",
        "print(f\"Gradient Boosting  hyperparameter Model: {metrics.r2_score(y_test, y_pred)} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XwR36TMrd8c"
      },
      "outputs": [],
      "source": [
        "# Now we will train the best model with the entire data set\n",
        "to_train_list = np.array(to_train)\n",
        "\n",
        "predicted = []\n",
        "for i in range(len(to_train_list)):\n",
        "    predicted.append(gb_base.predict(to_train_list[i].reshape(1, -1)))\n",
        "\n",
        "to_train[\"Actual\"] = y\n",
        "to_train[\"Predicted Result\"] = np.array(predicted)\n",
        "to_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WsWQdnMrlKN"
      },
      "outputs": [],
      "source": [
        "# plot the kde for both the actual and predicted results\n",
        "sns.kdeplot(to_train[\"Actual\"],\n",
        "            label=\"Actual Result\",\n",
        "            color=\"blue\")\n",
        "sns.kdeplot(to_train[\"Predicted Result\"],\n",
        "            label=\"Predicted Result\",\n",
        "            color=\"red\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2M8t0sKrpDA"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "import pickle\n",
        "file = open(\"body_fat_model.pkl\", \"wb\")\n",
        "pickle.dump(gb_base, file)\n",
        "file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}